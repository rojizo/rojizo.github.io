---
layout: chapter
title: Estadística descriptiva
number: 1
mathjax: true
chartjs: true
---

<h2>Los datos</h2>

<p>
  Queremos estudiar la relación entre algunos factores 
</p>




<p>
  <em>Variables cuantitativas.</em> Variables numéricas como 
  longitudes, tiempos, recuentos... Dentro de esta clase podemos distinguir dos
  tipos, las <em>continuas</em> en las que "cualquier" valor es posible, y las 
  <em>discretas</em> en las que los posibles valores forman un conjunto discreto.
</p>
<p>
  Con los valores de estas variables las operaciones matemáticas usuales 
  tienen sentido. No obstante, el resultado podría no tenerlo. 
</p>

<p>
  <em>Variables cualitativas<em> o </em>atributos.</em> Son aquellas que no son 
  numéricas. Por ejemplo características físicas como color de pelo. Algunas de 
  estas variables tienen un orden característico, por ejemplo si hablamos 
  de rangos militares, estos son objetivamente ordenables aún siendo datos cualitativos. 
  Llamaremos a estos datos <em>ordinales</em>.
</p>


<p>
  En general, trabajaremos con una colección (o varias colecciones) de valores 
  \[
    \{ x_1, x_2,x_3,\ldots,x_N \},
  \]
  que denominaremos <em>muestra</em>. A la cantidad de elementos, $N$, la llamaremos 
  <em>tamaño muestral</em>
</p>


<h2>Resumiendo los datos</h2>

<h3>Frecuencias, tartas y barras</h3>

<p>
  Supongamos que contamos con una muestra $\{x_i\}_{i=1}^N$. Definimos la 
  <em>frecuencia</em> del valor $x_i$ como el número de elementos de la muestra 
  iguales a $x_i$. Así, para cada posible valor de la muestra (sin repeticiones)
  tenemos una frecuecia con la que podríamos construir una tabla.
</p>

<p>
  Pensemos en el ejemplo
</p>

<!-- <p class="center">
  <canvas id="myChart"></canvas>
  <script>

    new Chart(document.getElementById("myChart"),{"type":"doughnut","data":{"labels":["Red","Blue","Yellow"],"datasets":[{"label":"My First Dataset","data":[300,50,100],"backgroundColor":["rgb(255, 99, 132)","rgb(54, 162, 235)","rgb(255, 205, 86)"]}]}});

    var ctx = document.getElementById('myChart').getContext('2d');
    // var chart = new Chart(ctx, {
    //     // The type of chart we want to create
    //     type: 'pie',
    //     data: {
    //       // The data for our dataset
    //       datasets: [{
    //         data: [0, 10, 5, 2, 20, 30, 45]
    //       }],
    //       labels: ['January', 'February', 'March', 'April', 'May', 'June', 'July'],
    //       // Configuration options go here
    //       options: {}
    //     }
    // });
  </script>
</p> -->



<h2>Principales estadísticos</h2>

<p>
\[
  \overline{X} = \frac1N \sum_{i=1}^N x_i
\]
</p>

<p>
  La <a id="varianzamuestral"><em>varianza muestral</em></a> es
  \[
    s^2 = \frac1{N-1}\sum_{i=1}^N (x_i-\overline{X})^2.
  \]
  La <a id="desviaciónmuestral"><em>desviación típica muestral</em></a> es
  \[
    s = \sqrt{s^2},
  \]
  que tiene las mismas unidades de la muestra $\{x_i\}$.
</p>


<div class="example">
  <p>
    Un científico está estudiando el clima en diferentes regiones del planeta. 
    Contacta con unos colegas suyos de Estados Unidos y les pide datos históricos 
    sobre la temperatura máximas en 
    <a href="https://www.nps.gov/yell/index.htm">Yellowstone</a> para sus 
    investigaciones. Dado que solo está interesado en la media y la desviación 
    típica, sus colegas le envían por correo electrónico esos datos 
    a partir de los datos históricos que tienen: 
    $\overline{X} = 52.72$ºF y $s = 18.53$ºF.
  </p>
  <p>
    Como el está trabajando en el Sistema Internacional, ha de transformar estos 
    valores a la escala Celsius. Por suerte la transformación es lineal
    \[
      \text{Celsius} = \frac1{1.8}(\text{Fahrenheit} - 32).
    \]
    Es posible calcular la media y desviación típica en la nueva
    escala sin los datos originales. En particular la temperatura media muestral y 
    la desviación típica muestral de la temperatura son $11.5$ºC y $10.3$ºC
    respectivamente.
  </p>
</div>

<h2>La desigualdad de Chebychev</h2>

<!-- <p>El matemático ruso <a href="https://www-history.mcs.st-andrews.ac.uk/Biographies/Chebyshev.html">P.L. Chebychev</a> transliteración de Чебышёв</p>-->

<p>
  Consideremos una muestra $X=\{x_i\}_{i=1}^N$. La desigualdad de Chebychev nos 
  proporciona una cota sobre el número de elementos de la muestra que están 
  <em>cerca</em> de media muestral. La condición de cercanía a $\overline{X}$ se 
  escribirá en términos de la desviación típica muestral y un parámetro libre 
  $k$. Así, se tienen infinitas desigualdades, una por cada valor de $k$.
</p>

<p class="theorem" id="desigualdadchevicheff">
  Sea $N_k$ el número de elementos de la muestra que pertenecen al 
  intervalo $(\overline{X}-k\,s, \overline{X}+k\,s)$, entonces
  \[
    \frac{N_k}{N} > 1-\frac1{k^2}.\tag{X}
  \]
</p>

<div class="proof">
  <p>
    Por comodidad, escribiremos $I_k=(\overline{X}-k\,s, \overline{X}+k\,s)$.
    De la definición de la <a href="#varianzamuestral">varianza muestral</a> 
    tenemos que
      $(N-1) s^2 = \sum_{i=1}^N (x_i-\overline{X})^2$
    Podemos dividir el sumatorio entre los que pertenecen al intervalo $I_k$ y los
    que no
    \[
      \begin{aligned}
        (N-1) s^2 &= \sum_{i=1}^N (x_i-\overline{X})^2 =
                     \sum_{x_i\notin I_k} (x_i-\overline{X})^2 +
                     \sum_{x_i\in I_k} (x_i-\overline{X})^2 \\
                  &\geq \sum_{x_i\notin I_k} (x_i-\overline{X})^2
                   \geq \sum_{x_i\notin I_k} (k\,s)^2 = (N-N_k)\,(k\,s)^2.
      \end{aligned}
    \]
    La primera desigualdad se obtiene ya hemos eliminando una cantidad positiva 
    ($(x_i-\overline{X})^2$ es siempre positivo). Para deducir la segunda basta 
    observar que, como los $x_i$ que estamos sumando no pertenecen a $I_k$, deben 
    estar a una distancia mayor o igual a $k\,s$ de $\overline{X}$, y por lo 
    tanto $(x_i-\overline{X})^2\geq (k\,s)^2$. Finalmente, dado que se está 
    sumando una constante, basta multiplicar por el número de veces que aparece, 
    i.e, el número de elementos de la muestra que no pertenecen a $I_k$. 
  </p>
  
  <p>
    Dividiendo por $N$ tenemos obtenemos
    \[
      \frac{N-1}{N}s^2 \geq \left(1-\frac{N_k}{N}\right)k^2\,s^2.
    \]
    Simplificando $s^2$ y dividiendo por $k^2$ a ambos lados queda
    \[
      \frac{N-1}{N}\frac1{k^2} \geq \left(1-\frac{N_k}{N}\right).
    \]
    Como $\frac{N-1}{N}\frac1{k^2} < \frac1{k^2}$,
    \[
      \frac1{k^2} > \left(1-\frac{N_k}{N}\right).
    \]
    Si reordenamos esta expresión obtenemos la desigualdad buscada.
  </p>
</div>


<script>
  function ff(id) {
    $(id+":bef")
  }
</script>


<h2>Muestras <em>vectoriales</em></h2>


<p>
  Consideremos que tenemos dos o más variables que están tomadas sobre la misma
  población, justamente como
  
   
</p>

<p>
  Definimos la <em>covarianza muestral</em> como 
  \[
    s_{XY} = \frac1{N-1}\sum_{i=1}^N (x_i-\overline{X})(y_i-\overline{Y})
  \]
  Esta cantidad tiene como unidades el producto de las de $\{x_i\}$ e $\{y_i\}$.
</p>

<p>
  El <em>coeficiente de correlación lineal de Pearson</em> es
  \[
    r_{XY} = \frac{s_{XY}}{s_X\,x_Y}.
  \]
  Mide la misma idea que la covarianza muestral, pero no depende de las 
  unidades, ya que lo hemos dividido por las desviaciones típicas muestrales. 
  Cuando no hay posible confusión sobre las muestras utilizadas es habitual 
  escribir $r$.
</p>

<p>
  Lo primero que debemos observar es que $r\in[-1,1]$. Veamos porque. 
  Consideremos los vectores $N$-dimensionales 
  $\vec{X} = (x_1-\overline{X},x_2-\overline{X},\ldots,x_N-\overline{X})$ y 
  $\vec{Y} = (y_1-\overline{Y},y_2-\overline{Y},\ldots,y_N-\overline{Y})$. 
  El <a href="http://mathworld.wolfram.com/DotProduct.html">coseno del ángulo $\alpha$
    que forman estos dos vectores</a> es
  \[
    \cos\alpha = \frac{\vec{X}\cdot\vec{Y}}{\lvert|\vec{X}\rvert|\, \lvert|\vec{Y}\rvert|}.
  \]
  Si sustituimos ahí las las identidades en coordenadas tenemos y multiplicando y dividiendo por $N-1$,
  \[
    \begin{aligned}
      \cos\alpha &= \frac{\sum_{i=1}^N (x_i-\overline{X})(y_i-\overline{Y})}{\sqrt{\sum_{i=1}^N (x_i-\overline{X})^2}\,\sqrt{\sum_{i=1}^N (y_i-\overline{Y})^2}} \\
                 &= \frac{(N-1)\sum_{i=1}^N (x_i-\overline{X})(y_i-\overline{Y})}{(N-1)\sqrt{\sum_{i=1}^N (x_i-\overline{X})^2}\,\sqrt{\sum_{i=1}^N (y_i-\overline{Y})^2}} \\
                 &= \frac{\color{red}{\sqrt{N-1}}\,\color{green}{\sqrt{N-1}}\color{blue}{\sum_{i=1}^N (x_i-\overline{X})(y_i-\overline{Y})}}
                         {\color{red}{\sqrt{\sum_{i=1}^N (x_i-\overline{X})^2}}\,\color{green}{\sqrt{\sum_{i=1}^N (y_i-\overline{Y})^2}}\color{blue}{(N-1)}} 
                 = \frac{\color{blue}{s_{XY}}}{\color{red}{s_X}\color{green}{s_Y}}.
    \end{aligned}
  \]
</p>


